{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/data-hackers/engenharia-de-features-transformando-dados-categ%C3%B3ricos-em-dados-num%C3%A9ricos-e5d3991df715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer, f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\") \n",
    "# apagando colunas que não auxiliam na predição\n",
    "df = df.drop([\"ano\", \"sequencial_candidato\", \"nome\"], axis=1)\n",
    "# lidando com as variaveis categoricas\n",
    "df = pd.get_dummies(df, columns = [\"uf\", \"partido\", \"cargo\", \"sexo\", \"grau\", \"estado_civil\", \"ocupacao\"]) \n",
    "# separando dados de treino e teste\n",
    "train, test = train_test_split(df, train_size=0.8) # separação entre treino e teste  \n",
    "\n",
    "train_y = train[[\"situacao\"]]\n",
    "train_X = train.drop([\"situacao\"], axis = 1)\n",
    "\n",
    "test_y = test[[\"situacao\"]]\n",
    "test_X = test.drop([\"situacao\"], axis = 1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_y.situacao)\n",
    "train_y = le.transform(train_y.situacao)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(test_y.situacao)\n",
    "test_y = le.transform(test_y.situacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "situacao\n",
       "eleito        1026\n",
       "nao_eleito    6596\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"situacao\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P: Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? \n",
    "\n",
    "R: Sim, Temos um dataset desbalanceado com mais classes do tipo \"não eleito\". mais ou menos 5 para 1, do que para o \"eleito\".\n",
    "\n",
    "P: Em que proporção? \n",
    "\n",
    "R: Mais de 5 para 1, ou seja a cada 1 eleito temos quase 6 não eleitos.\n",
    "\n",
    "P: Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador?\n",
    "\n",
    "R: Alguns algoritmos de ML tem dificuldade em em induzir um bom modelo a partir de conjutos de dados desbalanceados. Se classificarmos com dados da classe desbalanceados, os algoritmos podem não diferenciar  a classe minoritária das demais categorias, acreditando que estão agregando resultado devido à aparente alta acurácia. Essa falta de diferenciação pode ocasionar problemas visto que geralmente a classe minoritária é o cerne da questão, como no nosso caso, quem foi eleito.\n",
    "\n",
    "P: Como você poderia tratar isso? (10 pt.)\n",
    "\n",
    "R: Pode ser utilizado as técnicas de \"Reestruturação dos dados\". Dentro das ténicas de \"Reestruturação de dados\" pode ser feito o \"Undersamplig\", que é reduzir a distribuição dos dados das observações da classe majoritária, para tentar igualar a quantidade. Isso pode ser feito com \"Random Undersamplig\", que é a retirada aleatória de observações da classe majoritária, ou \"Fusão\" que é unir duas ou mais observações da classe majoritária para uma menor perda de informação. Outra forma é o Oversampling consite em criar novas observações da classe minoritária com o objetivo de igualar a proporção das categorias. Outra opção é escolher um algoritmo mais resilente, coletar mais dados e usar modelos penalizados ou utilizar outras métricas para treino.\n",
    "\n",
    "Fonte: https://medium.com/turing-talks/dados-desbalanceados-o-que-s%C3%A3o-e-como-evit%C3%A1-los-43df4f49732b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Treine: \n",
    "\n",
    "2.1 - um modelo de regressão logística, \n",
    "\n",
    "2.2 - uma árvore de decisão, \n",
    "\n",
    "2.3 - um modelo de adaboost, \n",
    "\n",
    "2.4 - um modelo de random forest e \n",
    "\n",
    "2.5 - um modelo de gradient boosting. \n",
    "\n",
    "2.6 - Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (10 pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lidando com as variáveis Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressao Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.5269897492365765\n",
      "F1: 0.9448760636330004\n",
      "ACC: 0.9022950819672131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gigi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_X, train_y)\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "y_pred = clf.predict(test_X)\n",
    "\n",
    "print(\"MCC:\", matthews_corrcoef(test_y, y_pred)) # métrica boa para avaliar modelos em dados desbalencados\n",
    "print(\"F1:\", f1_score(test_y, y_pred)) # O F1 só é baixo em dados desbalanceados se a classe minoritária tiver label 1\n",
    "print(\"ACC:\", accuracy_score(test_y, y_pred)) # Paradoxo da acurrácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC:  0.5749912854492889\n",
      "F1: 0.9477221807318894\n",
      "ACC: 0.9081967213114754\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(train_X, train_y)\n",
    "scoring = make_scorer(matthews_corrcoef)\n",
    "y_pred = clf.predict(test_X)\n",
    "\n",
    "print(\"MCC: \", matthews_corrcoef(test_y , y_pred))\n",
    "print(\"F1:\", f1_score(test_y , y_pred))\n",
    "print(\"ACC:\", accuracy_score(test_y , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.5871\n",
      "F1: 0.9489\n",
      "ACC: 0.9103\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "scoring = {\"mcc\" : make_scorer(matthews_corrcoef), \"f1\":\"f1\", \"acc\": \"accuracy\"}\n",
    "clf.fit(train_X, train_y)\n",
    "result_ros = cross_validate(clf, train_X, train_y, cv = 5, scoring=scoring)\n",
    "print(\"MCC:\", round(result_ros['test_mcc'].mean(), 4))\n",
    "print(\"F1:\", round(result_ros['test_f1'].mean(), 4))\n",
    "print(\"ACC:\", round(result_ros['test_acc'].mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf.fit(df_train_X, labels_train_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff2b62eaed73d2e1e1d38a205c492d76c68c9037b0d5e07e24413ea35a526a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
